# Runbook Operacional - Base de Datos PostgreSQL

**√öltima actualizaci√≥n**: 23 de Noviembre, 2025  
**Versi√≥n**: 1.0  
**Prop√≥sito**: Gu√≠a para diagnosticar y resolver problemas comunes de base de datos en producci√≥n

---

## üìä Monitoreo y Diagn√≥stico

### Endpoints de Salud

**Health Check Completo**
```bash
curl https://tu-app.replit.app/health
```

Respuesta esperada cuando est√° saludable:
```json
{
  "status": "healthy",
  "services": {
    "database": "up",
    "objectStorage": "up"
  },
  "poolMetrics": {
    "totalConnections": 2,
    "idleConnections": 1,
    "waitingQueries": 0,
    "maxConnections": 10,
    "utilizationPct": 20,
    "status": "normal"
  }
}
```

**Readiness Check (¬øPuede recibir tr√°fico?)**
```bash
curl https://tu-app.replit.app/readiness
```

### Interpretaci√≥n de M√©tricas del Pool

| M√©trica | Valor Normal | Precauci√≥n | Cr√≠tico |
|---------|--------------|------------|---------|
| **utilizationPct** | < 60% | 60-80% | > 80% |
| **waitingQueries** | 0-2 | 3-5 | > 5 |
| **status** | normal | high | saturated |

---

## üö® Problemas Comunes y Soluciones

### 1. Connection Timeout Errors

**S√≠ntomas**:
```
‚ùå Connection terminated due to connection timeout
Error: timeout exceeded when trying to connect
```

**Causas Comunes**:
- Pool saturado (todas las conexiones ocupadas)
- Queries lentas bloqueando conexiones
- Spike repentino de tr√°fico
- Problema con Neon (regi√≥n ca√≠da)

**Diagn√≥stico**:
1. Verificar m√©tricas del pool en `/health`
2. Revisar logs para queries lentas (>10 segundos)
3. Comprobar si `waitingQueries > 5`

**Soluci√≥n Inmediata**:
```bash
# 1. Verificar estado del pool
curl https://tu-app.replit.app/health | jq '.poolMetrics'

# 2. Si pool est√° saturado, reiniciar la app (libera conexiones)
# En Replit: Ir a "Tools" > "Restart"

# 3. Verificar que se recuper√≥
curl https://tu-app.replit.app/readiness
```

**Soluci√≥n a Largo Plazo**:
- Si ocurre frecuentemente: Aumentar `max` connections en `server/db.ts` (actualmente 10)
- Optimizar queries lentas identificadas en logs
- Considerar cacheo adicional para endpoints populares

---

### 2. Pool Saturation (Saturaci√≥n del Pool)

**S√≠ntomas**:
```
‚ö†Ô∏è HIGH POOL SATURATION: 90% (9/10)
‚ö†Ô∏è CONNECTION QUEUE BUILD-UP: 8 queries waiting
```

**Causas**:
- Muchas queries ejecut√°ndose simult√°neamente
- Queries lentas no terminan y bloquean el pool
- Pico de usuarios concurrentes

**Diagn√≥stico**:
```bash
# Ver m√©tricas en tiempo real
curl https://tu-app.replit.app/health | jq '.poolMetrics'

# Buscar queries lentas en los logs
# En Replit Console, buscar: "‚ö†Ô∏è Slow query detected"
```

**Soluci√≥n**:
1. **Inmediata**: Reiniciar app para limpiar pool
2. **Corto plazo**: Identificar y optimizar queries lentas
3. **Largo plazo**: 
   - Agregar √≠ndices faltantes
   - Implementar m√°s cacheo
   - Aumentar max connections si hardware lo soporta

---

### 3. Database Connection Failure

**S√≠ntomas**:
```
‚ùå Database pool error: connection refused
services: { database: "down" }
```

**Causas**:
- Credenciales incorrectas
- Neon en mantenimiento
- Red bloqueada
- Variable `POOLED_DATABASE_URL` no configurada

**Diagn√≥stico**:
```bash
# 1. Verificar variables de entorno
env | grep DATABASE_URL

# 2. Intentar conexi√≥n directa
psql $POOLED_DATABASE_URL -c "SELECT 1;"
```

**Soluci√≥n**:
1. Verificar `POOLED_DATABASE_URL` est√° configurada en Secrets
2. Probar conexi√≥n desde Replit Shell: `psql $POOLED_DATABASE_URL`
3. Si Neon est√° ca√≠do, esperar o contactar soporte de Neon
4. Verificar que no hay restricciones de IP

---

### 4. Slow Query Performance

**S√≠ntomas**:
```
‚ö†Ô∏è Slow query detected (15234ms): SELECT * FROM risks WHERE...
```

**Diagn√≥stico**:
1. Revisar logs para identificar query lenta
2. Analizar con `EXPLAIN ANALYZE`:
```sql
EXPLAIN ANALYZE
SELECT * FROM risks WHERE tenant_id = '123' AND deleted_at IS NULL;
```

**Soluci√≥n**:
1. **Agregar √≠ndices faltantes**:
```sql
-- Para queries con tenant_id y deleted_at
CREATE INDEX CONCURRENTLY idx_table_tenant_active 
ON table_name (tenant_id, deleted_at) 
WHERE deleted_at IS NULL;
```

2. **Optimizar query**:
   - Evitar `SELECT *`, usar columnas espec√≠ficas
   - Agregar condiciones WHERE m√°s restrictivas
   - Usar JOINs en vez de m√∫ltiples queries

3. **Implementar cacheo**:
   - Usar `distributedCache` para datos que no cambian frecuentemente
   - TTL recomendado: 5 minutos para datos "calientes"

---

### 5. Transaction Rollback Errors

**S√≠ntomas**:
```
‚ùå Transaction rolled back due to error
code: '40001' - serialization_failure
code: '40P01' - deadlock_detected
```

**Causas**:
- Conflictos de concurrencia (dos usuarios modifican mismo registro)
- Deadlock (dos transacciones esper√°ndose mutuamente)

**Soluci√≥n**:
- Sistema autom√°ticamente reintenta (ver `withRetry` en `server/db.ts`)
- Si persiste: Revisar l√≥gica de transacciones para reducir tiempo de lock
- Usar `SELECT FOR UPDATE NOWAIT` para fallar r√°pido en vez de esperar

---

### 6. Memory Issues

**S√≠ntomas**:
```
memory: { heapUsed: 950, heapTotal: 1024 }  // >90% usado
JavaScript heap out of memory
```

**Diagn√≥stico**:
```bash
curl https://tu-app.replit.app/health | jq '.deployment.memory'
```

**Soluci√≥n Inmediata**:
1. Reiniciar app para liberar memoria
2. Verificar que no hay memory leaks en queries grandes

**Soluci√≥n a Largo Plazo**:
- Implementar paginaci√≥n en endpoints que retornan muchos registros
- Usar streaming para exports grandes
- Aumentar `--max-old-space-size` si es necesario (actualmente 1024MB)

---

## üîç Comandos √ötiles de Diagn√≥stico

### Verificar Estado del Sistema
```bash
# Estado general
curl https://tu-app.replit.app/health | jq

# ¬øPuede recibir tr√°fico?
curl https://tu-app.replit.app/readiness | jq

# M√©tricas de performance
curl https://tu-app.replit.app/metrics | jq
```

### Logs en Producci√≥n
```bash
# En Replit Console, buscar patrones:
# - Errores de conexi√≥n
"connection timeout"

# - Queries lentas
"Slow query detected"

# - Saturaci√≥n del pool
"HIGH POOL SATURATION"

# - Queries en espera
"CONNECTION QUEUE BUILD-UP"
```

### Conectar a Base de Datos
```bash
# Desde Replit Shell
psql $POOLED_DATABASE_URL

# Ver conexiones activas
SELECT count(*), state FROM pg_stat_activity GROUP BY state;

# Ver queries lentas en ejecuci√≥n
SELECT pid, now() - pg_stat_activity.query_start AS duration, query 
FROM pg_stat_activity 
WHERE state = 'active' 
ORDER BY duration DESC;
```

---

## üìà Umbrales y Alertas

### Umbrales Configurados

| M√©trica | Warning | Critical | Acci√≥n |
|---------|---------|----------|--------|
| Pool Utilization | 80% | 90% | Logs autom√°ticos |
| Waiting Queries | 5 | 10 | Logs autom√°ticos |
| Query Duration | 10s | 30s | Logs autom√°ticos |
| Memory Usage | 80% | 95% | Reiniciar |

### Logs Autom√°ticos

El sistema genera logs cada 60 segundos con m√©tricas del pool:
```
üìä Pool Metrics: total=3/10 (30%), idle=2, waiting=0
```

Si detecta problemas, alerta autom√°ticamente en los logs de consola:
```
‚ö†Ô∏è HIGH POOL SATURATION: 90% (9/10) - Consider scaling or investigating slow queries
‚ö†Ô∏è CONNECTION QUEUE BUILD-UP: 8 queries waiting - Pool may be saturated
```

**Nota**: Las alertas actualmente se escriben en los logs de consola. Para producci√≥n, se recomienda configurar un sistema de alertas externo (como Sentry, DataDog, o PagerDuty) que monitoree estos logs y env√≠e notificaciones autom√°ticas al equipo de operaciones.

---

## üõ†Ô∏è Configuraci√≥n Actual

### Pool Configuration (server/db.ts)
```javascript
{
  max: 10,                     // M√°ximo 10 conexiones simult√°neas
  min: 0,                      // No mantener conexiones idle
  idleTimeoutMillis: 30000,    // Cerrar idle despu√©s de 30s
  connectionTimeoutMillis: 45000, // 45s timeout para cold starts
  statement_timeout: 60000,    // Queries timeout despu√©s de 60s
  keepAlive: true              // Mantener conexiones vivas
}
```

### Retry Logic
- **Max retries**: 3 intentos
- **Base delay**: 2 segundos
- **Exponential backoff**: 2s ‚Üí 4s ‚Üí 8s
- **Timeout delay**: Doble (4s ‚Üí 8s ‚Üí 16s)

### C√≥digos de Error Recuperables
- `57P01` - Admin shutdown (Neon recicla conexi√≥n)
- `08006` - Connection failure
- `08001` - Unable to connect
- `08004` - Connection rejected
- `53300` - Too many connections
- Mensajes con "timeout" o "Connection terminated"

---

## üìû Escalamiento

### Nivel 1: Auto-recuperaci√≥n
- Sistema reintenta autom√°ticamente (3 veces)
- Logs indican si se recuper√≥ o fall√≥ definitivamente

### Nivel 2: Acci√≥n del Operador
- Revisar `/health` y `/readiness`
- Reiniciar app si es necesario
- Aplicar soluciones de este runbook

### Nivel 3: Contactar Soporte
Si problema persiste despu√©s de:
- Reiniciar app
- Verificar configuraci√≥n
- Aplicar soluciones del runbook

**Informaci√≥n a Proveer**:
1. URL de `/health` output
2. Logs de los √∫ltimos 15 minutos
3. Timestamp exacto del problema
4. Queries lentas identificadas
5. M√©tricas del pool al momento del problema

---

## ‚úÖ Checklist de Salud Diaria

- [ ] Verificar `/health` retorna 200 OK
- [ ] Pool utilization < 60%
- [ ] No queries lentas en logs (>10s)
- [ ] Memory usage < 80%
- [ ] Waiting queries = 0
- [ ] Database status = "up"
- [ ] Object storage status = "up"

---

## üîÑ Mantenimiento Preventivo

### Semanal
- Revisar logs para patterns de queries lentas
- Verificar si hay √≠ndices faltantes
- Monitorear tendencias de uso del pool

### Mensual
- Analizar m√©tricas de performance (`/metrics`)
- Evaluar si aumentar max connections
- Revisar y limpiar logs antiguos
- Verificar integridad de backups de Neon

### Trimestral
- Revisar y actualizar este runbook
- Capacitar al equipo en nuevos procedimientos
- Evaluar necesidad de escalamiento de infraestructura

---

**Nota**: Este runbook est√° dise√±ado para operadores no t√©cnicos. Usa lenguaje simple y proporciona comandos copy-paste cuando sea posible.
