# Estrategia: Upstash Fuera del Camino Cr√≠tico (Latency-Resistant Architecture)

## üìä Evaluaci√≥n de la Estrategia

**Veredicto: ‚úÖ EXCELENTE estrategia** - Resuelve el problema sin cambiar proveedor.

### An√°lisis de cada punto:

---

## 1. ‚úÖ Fail-Open + Timeout Ultra Corto

**Estado:** ‚úÖ **YA IMPLEMENTADO**

- **Timeout actual:** 300ms (dentro del rango 100-300ms recomendado)
- **Comportamiento:** Si Upstash falla o es lento ‚Üí va directo a DB (que es r√°pida seg√∫n logs)
- **Resultado:** Upstash nunca congela pantallas

**Mejora aplicada:**
- Reducido timeout de 300ms a **200ms** para fail-fast m√°s agresivo
- Upstash queda completamente fuera del camino cr√≠tico

---

## 2. ‚ö†Ô∏è Stale-While-Revalidate

**Estado:** ‚ö†Ô∏è **PARCIALMENTE IMPLEMENTADO**

- **C√≥digo existe:** `staleMaxAgeMs` est√° en `SingleFlight` y `TwoTierCache`
- **Problema:** No est√° activado en endpoints cr√≠ticos
- **Soluci√≥n:** Activado con 10 minutos de stale para cat√°logos

**C√≥mo funciona:**
```typescript
// Si hay datos stale disponibles y fresh data se est√° calculando:
// ‚Üí Retorna stale inmediatamente (no espera)
// ‚Üí Actualiza en background
// ‚Üí Pr√≥xima request obtiene fresh data
```

**Beneficios:**
- Usuario nunca espera (siempre hay respuesta instant√°nea)
- Datos se refrescan en background
- Perfecto para cat√°logos que cambian poco

---

## 3. ‚úÖ SingleFlight / Request Coalescing

**Estado:** ‚úÖ **YA IMPLEMENTADO Y ACTIVO**

- **Funcionamiento:** Si 10 requests piden `catalogs:v3` al mismo tiempo:
  - Solo 1 hace el fetch
  - Los otros 9 esperan esa promesa
  - Evita "thundering herd" que vimos en logs

**Evidencia en c√≥digo:**
- `SingleFlight` class implementada
- Activo en `/api/processes/basic` y `/api/subprocesos`
- Deduplica requests concurrentes cuando cache est√° fr√≠o

---

## 4. ‚ö†Ô∏è TTL M√°s Largo + Prewarm

**Estado:** ‚ö†Ô∏è **MEJORADO, PERO FALTA PREWARM**

### TTLs Optimizados (Aplicados):

**Antes:**
- L1: 30 segundos (muy corto para cat√°logos)
- L2: 5 minutos (muy corto para cat√°logos est√°ticos)

**Ahora:**
- L1: **5 minutos** (cat√°logos est√°ticos)
- L2: **30 minutos** (cat√°logos est√°ticos)
- Stale-while-revalidate: **10 minutos**

**Cat√°logos que se benefician:**
- `processes-basic`: 30 min (estructura organizacional rara vez cambia)
- `subprocesos`: 30 min
- `macroprocesos`: 30 min
- `risk-levels`: 15 min (c√°lculos agregados)

### Prewarm (‚úÖ Implementado):

**Estado:** ‚úÖ **IMPLEMENTADO Y ACTIVO**

**Implementaci√≥n:**
- **Archivo:** `server/jobs/prewarm-cache.ts`
- **Servicio:** `CachePrewarmService` (singleton)
- **Frecuencia:** Cada 28 minutos (2 min antes de que expire L2 de 30 min)
- **Horario activo:** Solo entre 07:30 y 21:30 (horario laboral)
- **Cat√°logos precargados:**
  - `processes-basic:single-tenant` (con risk levels)
  - `subprocesos:single-tenant` (con risk levels)
  - `macroprocesos-basic:single-tenant`

**Caracter√≠sticas:**
- ‚úÖ Ejecuta autom√°ticamente al iniciar servidor
- ‚úÖ Ejecuta cada 25 minutos en background
- ‚úÖ No bloquea requests (async)
- ‚úÖ Maneja errores gracefully
- ‚úÖ Endpoint para trigger manual: `/api/cache/prewarm`
- ‚úÖ Endpoint para status: `/api/cache/prewarm/status`

**Integraci√≥n:**
- Se inicia autom√°ticamente en `server/index.ts` (5s despu√©s del startup)
- Puede ser llamado manualmente o desde Cloud Scheduler si es necesario

---

## üìà Impacto Esperado

### Antes (Upstash en camino cr√≠tico):
- ‚ùå Timeout de 28 segundos bloqueando requests
- ‚ùå "Thundering herd" cuando cache est√° fr√≠o
- ‚ùå M√∫ltiples requests concurrentes haciendo mismo fetch
- ‚ùå TTLs cortos causan cache misses frecuentes

### Despu√©s (Upstash fuera del camino cr√≠tico):
- ‚úÖ Timeout de 200ms ‚Üí fail-fast a DB (r√°pida)
- ‚úÖ SingleFlight deduplica requests concurrentes
- ‚úÖ Stale-while-revalidate ‚Üí respuesta instant√°nea siempre
- ‚úÖ TTLs largos ‚Üí menos cache misses
- ‚úÖ Prewarm ‚Üí cache siempre caliente en horas peak

### M√©tricas esperadas:
- **Latencia p95:** 200ms (timeout) + DB query (~100-300ms) = **<500ms total**
- **Cache hit rate:** 90%+ (con TTLs largos y prewarm)
- **Upstash calls:** 80% reducci√≥n (L1 cache + TTLs largos)
- **User experience:** Sin pantallas congeladas

---

## üéØ Recomendaciones Finales

### Prioridad Alta (Ya implementado):
1. ‚úÖ Fail-open con timeout 200ms
2. ‚úÖ SingleFlight activo
3. ‚úÖ Stale-while-revalidate activado (10 min)

### Prioridad Media (Mejoras aplicadas):
4. ‚úÖ TTLs aumentados (L1: 5min, L2: 30min)
5. ‚úÖ Prewarm implementado (ejecuta cada 25 minutos autom√°ticamente)

### Monitoreo:
- **M√©tricas clave:**
  - L2 timeout rate (debe ser <5%)
  - Cache hit rate (debe ser >90%)
  - L2 latency p95 (debe ser <200ms)
  - DB query latency (debe mantenerse <300ms)

---

## üí° Conclusi√≥n

**Esta estrategia es la correcta** porque:

1. ‚úÖ **No requiere cambiar proveedor** (Upstash puede seguir lejos)
2. ‚úÖ **Resuelve el problema de ra√≠z** (Upstash fuera del camino cr√≠tico)
3. ‚úÖ **Mejora UX dram√°ticamente** (sin pantallas congeladas)
4. ‚úÖ **Reduce costos** (menos llamadas a Upstash)
5. ‚úÖ **Escalable** (funciona con cualquier latencia de Upstash)

**Upstash puede ser lento, pero ya no importa** - el sistema es resiliente y siempre responde r√°pido.

---

## üìù Pr√≥ximos Pasos

1. **Monitorear m√©tricas** despu√©s del deploy
2. **Implementar prewarm** si cache misses siguen siendo altos
3. **Ajustar TTLs** seg√∫n patrones de uso reales
4. **Considerar L3 cache** (CDN) para cat√°logos completamente est√°ticos

