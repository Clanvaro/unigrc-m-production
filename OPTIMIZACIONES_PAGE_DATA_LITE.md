# Optimizaciones Implementadas para `/api/risks/page-data-lite`

## ‚úÖ Optimizaciones Implementadas

### 1. **Optimizaci√≥n de `getRiskStats()` con Agregaci√≥n SQL** ‚úÖ

**Antes:** Tra√≠a TODOS los registros de `risks` y calculaba agregados en memoria
```typescript
// Tra√≠a todos los registros (puede ser miles)
const stats = await db.select({ status, inherentRisk, isDeleted }).from(risks);
// Luego filtraba y contaba en memoria
const active = stats.filter(s => s.status === 'active' && !s.isDeleted).length;
```

**Despu√©s:** Una sola query SQL con agregaci√≥n
```sql
SELECT 
  COUNT(*)::int as total,
  COUNT(*) FILTER (WHERE deleted_at IS NULL AND status = 'active')::int as active,
  COUNT(*) FILTER (WHERE deleted_at IS NULL AND status = 'inactive')::int as inactive,
  COUNT(*) FILTER (WHERE deleted_at IS NOT NULL)::int as deleted,
  -- ... m√°s agregados
FROM risks
```

**Impacto esperado:** 
- Reduce transferencia de datos de ~MB a ~KB
- Reduce tiempo de query de segundos a milisegundos
- Reduce uso de memoria significativamente

### 2. **Logging Detallado de Redis** ‚úÖ

**Agregado:**
- Tiempo de `redis.get()` en cache hit/miss
- Tiempo de `redis.set()` al guardar cach√©
- Tama√±o de respuesta en KB

**Logs ahora muestran:**
```
[page-data-lite] CACHE HIT { redisGetMs: 45, total: 50 }
[page-data-lite] CACHE MISS { redisGetMs: 120 }
[page-data-lite] CACHE SET { redisSetMs: 250, responseSizeKB: 1250 }
```

**Beneficio:** Permite identificar si Redis/Upstash es el cuello de botella

### 3. **Limitaci√≥n de Concurrencia de Queries** ‚úÖ

**Problema identificado:**
- Pool de conexiones limitado a 4 conexiones
- Cloud Run con concurrency=10 permite m√∫ltiples requests simult√°neos
- Endpoint ejecutaba 9 queries en paralelo con `Promise.all()`
- Esto causaba **pool starvation**: requests esperando conexiones disponibles (88-195s de espera)

**Soluci√≥n implementada:**
- Ejecutar queries en **batches de 2 queries** en lugar de todas en paralelo
- Respeta el l√≠mite del pool (pool=4, max 2 queries concurrentes por request)
- Agregado logging de m√©tricas del pool antes y despu√©s de las queries

**C√≥digo:**
```typescript
// Antes: 9 queries en paralelo
await Promise.all([risksPromise, ownersPromise, statsPromise, ...]);

// Despu√©s: Batches de 2 queries
const CONCURRENT_QUERIES = 2;
for (let i = 0; i < queries.length; i += CONCURRENT_QUERIES) {
  const batch = queries.slice(i, i + CONCURRENT_QUERIES);
  await Promise.all(batch.map(q => q.fn()));
}
```

**Impacto esperado:**
- Elimina pool starvation
- Reduce tiempo de espera de conexiones de 88-195s a <5s
- Permite que m√∫ltiples requests compartan el pool sin saturarlo

### 4. **Logging de Pool Metrics** ‚úÖ

**Agregado:**
- M√©tricas del pool **antes** de ejecutar queries
- M√©tricas del pool **despu√©s** de cada batch de queries
- M√©tricas del pool **despu√©s** de todas las queries

**Logs muestran:**
```
[page-data-lite] Pool metrics BEFORE queries {
  total: 4, max: 4, idle: 2, active: 2, waiting: 0, utilization: '50%'
}
[page-data-lite] Batch 1 completed in 250ms {
  poolTotal: 4, poolActive: 2, poolWaiting: 0
}
[page-data-lite] Pool metrics AFTER queries {
  total: 4, max: 4, idle: 3, active: 1, waiting: 0, utilization: '25%'
}
```

**Beneficio:** Permite confirmar si el problema es pool starvation (waiting > 0 o total=4/4 constante)

---

## üìã Optimizaciones Pendientes (Recomendadas)

### 3. **√çndices para `getRisksLite()`**

El LATERAL JOIN en `getRisksLite()` necesita estos √≠ndices para optimizar:

```sql
-- √çndice compuesto para el LATERAL JOIN
CREATE INDEX IF NOT EXISTS idx_risk_process_links_risk_created 
ON risk_process_links(risk_id, created_at DESC NULLS LAST)
WHERE responsible_override_id IS NOT NULL;

-- √çndice parcial adicional (opcional, pero mejora a√∫n m√°s)
CREATE INDEX IF NOT EXISTS idx_risk_process_links_responsible_override 
ON risk_process_links(risk_id, responsible_override_id, created_at DESC NULLS LAST)
WHERE responsible_override_id IS NOT NULL;
```

**Impacto esperado:** Reduce tiempo de `getRisksLite()` de segundos a <500ms

**C√≥mo aplicar:**
```bash
# Crear migraci√≥n
psql $DATABASE_URL -c "
CREATE INDEX IF NOT EXISTS idx_risk_process_links_risk_created 
ON risk_process_links(risk_id, created_at DESC NULLS LAST)
WHERE responsible_override_id IS NOT NULL;
"
```

### 4. **Optimizar SELECT * en Cat√°logos** (Opcional)

Los cat√°logos (`getGerencias`, `getMacroprocesos`, `getProcesses`) usan `SELECT *`. 

**Evaluaci√≥n:**
- ‚úÖ Ya tienen cach√© Redis (60s TTL)
- ‚úÖ Son relativamente peque√±os (<1000 registros t√≠picamente)
- ‚ö†Ô∏è SELECT espec√≠fico reducir√≠a transferencia pero el impacto es menor

**Si decides optimizar:**
```typescript
// En lugar de:
db.select().from(gerencias)

// Usar:
db.select({
  id: gerencias.id,
  code: gerencias.code,
  name: gerencias.name,
  level: gerencias.level,
  order: gerencias.order,
  parentId: gerencias.parentId,
  managerId: gerencias.managerId,
  status: gerencias.status,
  // No incluir: description, createdBy, updatedBy, deletedBy, deletionReason, createdAt, updatedAt
}).from(gerencias)
```

**Impacto esperado:** Reducci√≥n de ~20-30% en tama√±o de respuesta (menor que getRiskStats)

---

## üîß Configuraci√≥n de Infraestructura

### 5. **Ajustar Concurrency en Cloud Run** ‚ö†Ô∏è CR√çTICO

**Problema:**
- Cloud Run tiene `concurrency=10` (permite 10 requests simult√°neos por instancia)
- Pool de conexiones es `pool=4` (solo 4 conexiones disponibles)
- Con 10 requests simult√°neos √ó 2 queries por request = 20 queries intentando usar 4 conexiones
- Esto causa **pool starvation masivo**

**Soluci√≥n recomendada:**

```bash
# Reducir concurrency a 1-2 para respetar pool=4
gcloud run services update unigrc-backend \
  --concurrency=1 \
  --region=us-central1
```

**O si necesitas m√°s throughput, aumentar pool primero:**
```bash
# Opci√≥n 1: Aumentar pool a 8-10 (si Cloud SQL lo permite)
# Luego puedes mantener concurrency=2-3
DB_POOL_MAX=8

# Opci√≥n 2: Reducir concurrency a 1-2 (m√°s seguro)
--concurrency=1
```

**F√≥rmula:**
```
pool_size >= concurrency √ó queries_por_request
4 >= 10 √ó 2  ‚ùå (causa starvation)
4 >= 1 √ó 2   ‚úÖ (funciona)
8 >= 2 √ó 2   ‚úÖ (mejor balance)
```

**Objetivo:** Eliminar pool starvation confirmado por logs (waiting > 0)

### 6. **Verificar Configuraci√≥n de Pool de Conexiones**

**No est√°s usando Prisma**, est√°s usando `pg` Pool directamente. La configuraci√≥n est√° en `server/db.ts`:

```typescript
// Ya est√° optimizado para Cloud SQL:
poolMax = 4  // Configurable via DB_POOL_MAX env var
poolMin = 2
connectionTimeoutMillis = 60000
statement_timeout = 30000
```

**Verificar:**
- ‚úÖ Pool max ya est√° bajo (4 conexiones por instancia)
- ‚úÖ Timeout de statement configurado (30s)
- ‚ö†Ô∏è Verificar que `DB_POOL_MAX=4` est√© en variables de entorno

**Si necesitas reducir m√°s:**
```bash
# En Cloud Run, agregar variable de entorno:
DB_POOL_MAX=2
```

---

## üîç Diagn√≥stico de Redis/Upstash

### 7. **Verificar Latencia de Upstash**

Con el nuevo logging, revisa los logs:

```bash
# Buscar logs de Redis
gcloud logging read "resource.type=cloud_run_revision AND jsonPayload.redisGetMs>100" --limit=50

# Si redisGetMs > 200ms consistentemente:
# - Verificar regi√≥n de Upstash (debe estar cerca de Cloud Run)
# - Verificar rate limits de Upstash REST API
# - Considerar usar Redis directo en lugar de REST API
```

**Si Redis es lento:**
- Opci√≥n 1: Cambiar regi√≥n de Upstash a la misma que Cloud Run
- Opci√≥n 2: Usar Redis directo (no REST API) si Upstash lo soporta
- Opci√≥n 3: Aumentar timeout de cach√© o deshabilitar temporalmente para diagn√≥stico

---

## üìä M√©tricas Esperadas Despu√©s de Optimizaciones

### Antes:
- `getRiskStats()`: 5-30s (dependiendo de cantidad de riesgos)
- `page-data-lite` total: 88-195s
- Redis get: No medido

### Despu√©s (esperado):
- `getRiskStats()`: <100ms (agregaci√≥n SQL)
- `page-data-lite` total: 2-10s (con cach√©), 5-15s (sin cach√©)
- Redis get: <100ms (si regi√≥n correcta)

---

## üöÄ Pr√≥ximos Pasos

1. ‚úÖ **Implementado:** Optimizaci√≥n de `getRiskStats()` con agregaci√≥n SQL
2. ‚úÖ **Implementado:** Logging detallado de Redis
3. ‚úÖ **Implementado:** Limitaci√≥n de concurrencia de queries (batches de 2)
4. ‚úÖ **Implementado:** Logging de pool metrics antes/despu√©s
5. ‚ö†Ô∏è **CR√çTICO:** Ajustar `concurrency` en Cloud Run a 1-2 (o aumentar pool)
6. ‚è≥ **Pendiente:** Crear √≠ndices para `getRisksLite()`
7. ‚è≥ **Pendiente:** Monitorear logs para confirmar eliminaci√≥n de pool starvation

---

## üìù Notas Adicionales

### Sobre el "doble fetch"
Si ves dos requests seguidos al mismo endpoint:
- Revisar `useQuery` en el frontend
- Verificar que no haya m√∫ltiples `useEffect` disparando el mismo fetch
- Considerar `staleTime` m√°s alto para evitar refetches innecesarios

### Sobre Prisma
**No est√°s usando Prisma**, est√°s usando Drizzle ORM con `pg` Pool. Las recomendaciones de Prisma no aplican. Tu configuraci√≥n de pool ya est√° optimizada.
